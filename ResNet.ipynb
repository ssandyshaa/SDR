{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10785 Project Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time, random, copy, csv\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import foolbox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Papernot's attack on resnet18 trained without SDR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Setup ResNet18 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "################################################\n",
    "# Dataset classes & functions\n",
    "################################################\n",
    "\n",
    "def parse_data(path):\n",
    "    count = 0\n",
    "    img_list = []\n",
    "    ID_list = []\n",
    "    for root, dirs, files in os.walk(path): \n",
    "        for file in files: # all files under the same class folder\n",
    "            if file.endswith('.jpg') and not file.startswith('._'):\n",
    "                fpath = os.path.join(root, file)\n",
    "                img_list.append(fpath)\n",
    "                ID_list.append(int(root.split('/')[-1]))\n",
    "        #         count += 1\n",
    "        #         if count >= 6000:\n",
    "        #             break\n",
    "        # if count >= 6000:\n",
    "        #     break\n",
    "    num_classes = len(set(ID_list))\n",
    "    print('{}\\t\\t{}\\n{}\\t\\t{}'.format('#Images', '#Labels', len(img_list), num_classes))\n",
    "    return img_list, ID_list, num_classes\n",
    "\n",
    "def parse_data_test(path):\n",
    "    count = 0\n",
    "    img_dict = dict()\n",
    "    for root, dirs, files in os.walk(path): \n",
    "        for file in files: # all files under the same class folder\n",
    "            if file.endswith('.jpg') and not file.startswith('._'):\n",
    "                fpath = os.path.join(root, file)\n",
    "                fidx = int(file.replace('.jpg', ''))\n",
    "                img_dict[fidx] = fpath\n",
    "    return img_dict\n",
    "\n",
    "class FaceDataset(Dataset):\n",
    "    def __init__(self, file_list, target_list, num_classes):\n",
    "        self.file_list = file_list\n",
    "        self.target_list = target_list\n",
    "        self.num_class = num_classes\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.file_list[idx])\n",
    "        img = torchvision.transforms.ToTensor()(img)\n",
    "        label = self.target_list[idx]\n",
    "        return img, label\n",
    "\n",
    "class AdvDataset(Dataset):\n",
    "    def __init__(self, adv_samples, target_list, num_classes): \n",
    "        self.adv_samples = adv_samples\n",
    "        self.target_list = target_list\n",
    "        self.num_class = num_classes\n",
    "\n",
    "    def __len__(self):\n",
    "        return adv_samples.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.adv_samples[idx]\n",
    "        img = torch.from_numpy(img)\n",
    "        label = self.target_list[idx]\n",
    "        return img, label\n",
    "    \n",
    "class FaceDataset_test(Dataset):\n",
    "    def __init__(self, img_dict):\n",
    "        self.imgs = img_dict\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.imgs[idx])\n",
    "        img = torchvision.transforms.ToTensor()(img)\n",
    "        return img\n",
    "\n",
    "################################################\n",
    "# Network n loss classes & functions\n",
    "################################################\n",
    "\n",
    "def init_weights(module):\n",
    "    if type(module) == nn.Conv2d or type(module) == nn.Linear:\n",
    "        torch.nn.init.xavier_normal_(module.weight.data)\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ResBlock, self).__init__()\n",
    "        stride = 1\n",
    "        self.downsample = None\n",
    "        if in_channels != out_channels: # downsampling with stride = 2 required\n",
    "            stride = 2\n",
    "            down_layer = nn.Conv2d(in_channels = in_channels, out_channels = out_channels,\n",
    "                                   kernel_size = 2, stride = stride, bias = False)\n",
    "            down_bn = nn.BatchNorm2d(num_features = out_channels)\n",
    "            self.downsample = nn.Sequential(down_layer, down_bn)\n",
    "\n",
    "\n",
    "        self.block = nn.Sequential(nn.Conv2d(in_channels = in_channels, out_channels = out_channels,\n",
    "                                             kernel_size = 3, stride = stride, padding = 1, bias = False), # half the map size if need be\n",
    "                                   nn.BatchNorm2d(num_features = out_channels),\n",
    "                                   nn.ReLU(inplace = True),\n",
    "                                   nn.Conv2d(in_channels = out_channels, out_channels = out_channels,\n",
    "                                             kernel_size = 3, stride = 1, padding = 1, bias = False), # preserve map size\n",
    "                                   nn.BatchNorm2d(num_features = out_channels))\n",
    "\n",
    "        self.final_nonlinear = nn.ReLU(inplace = True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # I referenced the original pytorch resnet impelmentation here: https://pytorch.org/docs/stable/_modules/torchvision/models/resnet.html#resnet18\n",
    "        residual = x\n",
    "        out = self.block(x)\n",
    "        if self.downsample != None:\n",
    "            residual = self.downsample(residual)\n",
    "        out += residual\n",
    "        out = self.final_nonlinear(out)\n",
    "        return out\n",
    "\n",
    "class Face_CNN(nn.Module):\n",
    "    def __init__(self, num_in_channels, nums_hidden_channels, num_classes):\n",
    "        super(Face_CNN, self).__init__()\n",
    "        # Before residual components\n",
    "        in_layer = nn.Conv2d(in_channels = num_in_channels, \n",
    "                             out_channels = nums_hidden_channels[0],\n",
    "                             kernel_size = 3, stride = 1, padding = 1, bias = False)\n",
    "        in_bn = nn.BatchNorm2d(num_features = nums_hidden_channels[0])\n",
    "        in_nonlinear = nn.ReLU(inplace = True)\n",
    "        self.layers = [in_layer, in_bn, in_nonlinear]\n",
    "\n",
    "        # Residual components\n",
    "        for i in range(len(nums_hidden_channels) - 1):\n",
    "            in_channels = nums_hidden_channels[i]\n",
    "            out_channels = nums_hidden_channels[i+1]\n",
    "            self.layers.append(ResBlock(in_channels, out_channels))\n",
    "\n",
    "        # After residual components: can either go to an MLP clf or flatten as an embedding\n",
    "        self.layers = nn.Sequential(*self.layers)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.linear_clf = nn.Linear(nums_hidden_channels[-1], num_classes, bias = False)\n",
    "\n",
    "    def forward(self, x, evalMode = False):\n",
    "        output = x\n",
    "        output = self.layers(output) # conv layers\n",
    "        output = self.avgpool(output).view(output.size(0), -1) # embedding\n",
    "        clf_out = self.linear_clf(output)\n",
    "        return clf_out\n",
    "\n",
    "################################################\n",
    "# Training n testing classes & functions\n",
    "################################################\n",
    "\n",
    "def train(model, optimizer, criterion, train_loader, val_loader, num_epochs, task = 'Classification'):\n",
    "    print('[LOG] Start Training...')\n",
    "    \n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        curr_avg_loss = 0.0\n",
    "        avg_loss = 0.0\n",
    "\n",
    "        curr_t = time.time()\n",
    "\n",
    "        for batch_num, (data, tgts) in enumerate(train_loader):\n",
    "            if CUDA:\n",
    "                data = data.cuda()\n",
    "                tgts = tgts.cuda()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(data)\n",
    "\n",
    "            loss = criterion(outputs, tgts.long())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            curr_avg_loss += loss.item()\n",
    "\n",
    "            btemp = 50\n",
    "\n",
    "            if batch_num % btemp == btemp - 1:\n",
    "                t_elapsed = (time.time() - curr_t)/batch_num\n",
    "                est_t_rm = t_elapsed * (6425 - batch_num) / 60\n",
    "                print('Epoch: {}\\tBatch: {}\\tAvg-Loss: {:.4f}\\tTime-Remaining: {:.3f}mins'.format(epoch+1, batch_num+1, curr_avg_loss/btemp, est_t_rm))\n",
    "                curr_avg_loss = 0.0\n",
    "\n",
    "            torch.cuda.empty_cache()\n",
    "            del data\n",
    "            del tgts\n",
    "            del loss\n",
    "\n",
    "        epoch_i = epoch + 4\n",
    "\n",
    "        model_path = 'Res18_0308_epoch_%i.pt' % epoch_i\n",
    "        save_model(model, model_path)\n",
    "        print('[LOG] Finish training the current epoch, model saved to %s' % model_path)\n",
    "\n",
    "        if task == 'Classification':\n",
    "            val_loss, val_acc = test_classify(model, val_loader, criterion)\n",
    "            train_loss, train_acc = test_classify(model, train_loader, criterion)\n",
    "            print('Train Loss: {:.4f}\\tTrain Accuracy: {:.4f}\\tVal Loss: {:.4f}\\tVal Accuracy: {:.4f}'.format(train_loss, train_acc, val_loss, val_acc))\n",
    "\n",
    "        elif task == 'Verification':\n",
    "            val_loss, val_acc = test_verify(model, val_loader, criterion)\n",
    "            train_loss, train_acc = test_verify(model, train_loader, criterion)\n",
    "            print('Train Loss: {:.4f}\\tTrain Accuracy: {:.4f}\\tVal Loss: {:.4f}\\tVal Accuracy: {:.4f}'.format(train_loss, train_acc, val_loss, val_acc))\n",
    "\n",
    "def save_model(model, path):\n",
    "    torch.save(model.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Images\t\t#Labels\n",
      "4601\t\t2300\n",
      "[LOG] Setting up model...\n",
      "Model is loaded\n"
     ]
    }
   ],
   "source": [
    "#Specify the model\n",
    "batch_size = 128\n",
    "CUDA = torch.cuda.is_available()\n",
    "DEVICE = 'cuda' if CUDA else 'cpu'\n",
    "\n",
    "# print('[LOG] Loading training and validation data...')\n",
    "# img_list, label_list, num_classes = parse_data('hw2p2_check/train_data/medium')\n",
    "# train_dataset = FaceDataset(img_list, label_list, num_classes)\n",
    "# train_dataloader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True, num_workers = 4, drop_last = False)\n",
    "\n",
    "img_list, label_list, num_classes = parse_data('hw2p2_check/validation_classification/medium')\n",
    "val_dataset = FaceDataset(img_list, label_list, num_classes)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size = batch_size, num_workers = 4, drop_last = False)\n",
    "\n",
    "print('[LOG] Setting up model...')\n",
    "hiddens = [64, 64, 64, 128, 128, 256, 256, 512, 512]\n",
    "model = Face_CNN(3, hiddens, num_classes).to(DEVICE)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001, weight_decay = 0.0001)\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model_path = 'Res18_0308_epoch_4.pt'\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval()\n",
    "print ('Model is loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Generate adversarial samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Generate_Adversarial_Samples(model, loader):\n",
    "    model.eval()\n",
    "    if CUDA:\n",
    "        model = model.cuda()\n",
    "    fmodel = foolbox.models.PyTorchModel(model, bounds=(0, 1), num_classes=num_classes)\n",
    "    attack = foolbox.attacks.FGSM(fmodel)\n",
    "    for batch_num, (data, tgts) in enumerate(loader):\n",
    "        print (batch_num)\n",
    "        if CUDA:\n",
    "            data = data.cuda()\n",
    "            tgts = tgts.cuda()\n",
    "        for i in range(data.shape[0]):\n",
    "            w = np.asarray(data[i].view(3,32,32).cpu())\n",
    "            l = tgts[i].cpu().numpy()\n",
    "            if batch_num == 0 and i == 0:\n",
    "                adv_samples = attack(w, l).reshape(1,3,32,32)\n",
    "            else:\n",
    "                adv_samples = np.concatenate([adv_samples, attack(w, l).reshape(1,3,32,32)])\n",
    "    return adv_samples  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Generate Adv Samples\n",
    "adv_samples = Generate_Adversarial_Samples(model, val_dataloader)\n",
    "#Save the adversarial samples\n",
    "np.save('val_adv_samples.npy', adv_samples)\n",
    "print ('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the adversarial samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Original img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "orig = np.uint8(val_dataset.__getitem__(0)[0].numpy()*255)\n",
    "orig_ = orig.transpose(1,2,0)\n",
    "plt.imshow(orig_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perturbed img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "w = np.uint8(adv_samples[0]*255)\n",
    "w1 = w.transpose(1,2,0)\n",
    "plt.imshow(w1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Test model performance under attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_classify(model, loader, criterion):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    acc = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch_num, (data, tgts) in enumerate(loader):\n",
    "        if CUDA:\n",
    "            data = data.cuda()\n",
    "            tgts = tgts.cuda()\n",
    "        outputs = model(data)\n",
    "\n",
    "        _, pred_labels = torch.max(F.softmax(outputs, dim = 1), 1)\n",
    "        pred_labels = pred_labels.view(-1)\n",
    "\n",
    "        loss = criterion(outputs, tgts.long())\n",
    "\n",
    "        acc += torch.sum(torch.eq(pred_labels, tgts)).item()\n",
    "        batch_size = len(tgts)\n",
    "        total += batch_size\n",
    "        test_loss += loss.item() * batch_size\n",
    "\n",
    "        del data\n",
    "        del tgts\n",
    "\n",
    "    model.train()\n",
    "    return test_loss*1.0/total, acc*1.0/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy on non-adversarial samples: 0.7370136926755053\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "val_loss, val_acc = test_classify(model, val_dataloader, criterion)\n",
    "#Validation accuracy on non-adversarial samples\n",
    "print ('Validation Accuracy on non-adversarial samples: '+ str(val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy on non-adversarial samples: 0.0\n"
     ]
    }
   ],
   "source": [
    "#Create Adversarial Dataset\n",
    "adv_dataset = AdvDataset(adv_samples, label_list, num_classes)\n",
    "adv_dataloader = DataLoader(adv_dataset, batch_size = batch_size, num_workers = 4, drop_last = False)\n",
    "adv_loss, adv_acc = test_classify(model, adv_dataloader, criterion)\n",
    "#Validation accuracy on adversarial samples\n",
    "print ('Validation Accuracy on non-adversarial samples: '+ str(adv_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Papernot's attack on resnet18 trained with SDR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded\n"
     ]
    }
   ],
   "source": [
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "hiddens = [64, 64, 64, 128, 128, 256, 256, 512, 512]\n",
    "model = Face_CNN(3, hiddens, 2300)\n",
    "\n",
    "model_path = os.path.join('model_epoch_0_ckpt.pt')\n",
    "model.load_state_dict(torch.load(model_path, map_location = DEVICE))\n",
    "model = model.to(DEVICE)\n",
    "print('model loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy on non-adversarial samples: 0.72245164094762\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "val_loss, val_acc = test_classify(model, val_dataloader, criterion)\n",
    "#Validation accuracy on non-adversarial samples\n",
    "print ('Validation Accuracy on non-adversarial samples: '+ str(val_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tested on adversarial samples generated using the non-sdr trained model (surrogate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy on non-adversarial samples: 0.6494240382525538\n"
     ]
    }
   ],
   "source": [
    "#Create Adversarial Dataset\n",
    "adv_dataset = AdvDataset(adv_samples, label_list, num_classes)\n",
    "adv_dataloader = DataLoader(adv_dataset, batch_size = batch_size, num_workers = 4, drop_last = False)\n",
    "adv_loss, adv_acc = test_classify(model, adv_dataloader, criterion)\n",
    "#Validation accuracy on adversarial samples\n",
    "print ('Validation Accuracy on non-adversarial samples: '+ str(adv_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tested on adversarial samples generated using the sdr trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Generate Adv Samples\n",
    "adv_samples = Generate_Adversarial_Samples(model, val_dataloader)\n",
    "#Save the adversarial samples\n",
    "np.save('val_adv_samples_sdr.npy', adv_samples)\n",
    "print ('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy on non-adversarial samples: 0.0\n"
     ]
    }
   ],
   "source": [
    "#Create Adversarial Dataset\n",
    "adv_dataset = AdvDataset(adv_samples, label_list, num_classes)\n",
    "adv_dataloader = DataLoader(adv_dataset, batch_size = batch_size, num_workers = 4, drop_last = False)\n",
    "adv_loss, adv_acc = test_classify(model, adv_dataloader, criterion)\n",
    "#Validation accuracy on adversarial samples\n",
    "print ('Validation Accuracy on adversarial samples: '+ str(adv_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Another trained model with higher validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded\n"
     ]
    }
   ],
   "source": [
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "hiddens = [64, 64, 64, 128, 128, 256, 256, 512, 512]\n",
    "model1 = Face_CNN(3, hiddens, 2300)\n",
    "\n",
    "model_path1 = os.path.join('model_epoch_14_ckpt.pt')\n",
    "model1.load_state_dict(torch.load(model_path1, map_location = DEVICE))\n",
    "model1 = model1.to(DEVICE)\n",
    "print('model loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy on non-adversarial samples: 0.7346229080634644\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "val_loss, val_acc = test_classify(model1, val_dataloader, criterion)\n",
    "#Validation accuracy on non-adversarial samples\n",
    "print ('Validation Accuracy on non-adversarial samples: '+ str(val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/foolbox/attacks/base.py:129: UserWarning: Not running the attack because the original input is already misclassified and the adversarial thus has a distance of 0.\n",
      "  warnings.warn('Not running the attack because the original input'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "#Generate Adv Samples\n",
    "adv_samples1 = Generate_Adversarial_Samples(model1, val_dataloader)\n",
    "#Save the adversarial samples\n",
    "np.save('val_adv_samples_sdr1.npy', adv_samples1)\n",
    "print ('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_samples = adv_samples1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy on non-adversarial samples: 0.0\n"
     ]
    }
   ],
   "source": [
    "#Create Adversarial Dataset\n",
    "adv_dataset = AdvDataset(adv_samples, label_list, num_classes)\n",
    "adv_dataloader = DataLoader(adv_dataset, batch_size = batch_size, num_workers = 4, drop_last = False)\n",
    "adv_loss, adv_acc = test_classify(model1, adv_dataloader, criterion)\n",
    "#Validation accuracy on adversarial samples\n",
    "print ('Validation Accuracy on adversarial samples: '+ str(adv_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = model.cpu()\n",
    "# fmodel = foolbox.models.PyTorchModel(model, bounds=(0, 1), num_classes=num_classes, device='cpu')\n",
    "# attack = foolbox.attacks.FGSM(fmodel)\n",
    "# model(data[0].view(1,3,32,32))\n",
    "# w = np.asarray(data[0].view(3,32,32))\n",
    "# fmodel.predictions(w)\n",
    "# l = tgt[0].numpy()\n",
    "# e = attack(w,l)\n",
    "# print ('done')\n",
    "\n",
    "# x = np.zeros((1,2,3))\n",
    "# y = np.zeros((1,2,3))\n",
    "# w = np.concatenate([x,y])\n",
    "# w.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
